# User Coding Skill - MOI Data Analytics V2

## For: Shivang Patel (shivang@crtx.in)
## When: Working with any coder on this project

---

## My Coding Philosophy

**"No code without clear documentation and my approval at each step."**

## How I Work with Coders

### Rule #1: Always Break Down the Problem
- **NEVER** let a coder start coding immediately
- **ALWAYS** demand they break the work into phases first
- **REQUIRE** documentation before approval to proceed

### Rule #2: Phase-by-Phase Validation
- I test **each phase** before allowing the next
- **NO exceptions** - if I'm not happy, we don't proceed
- Each phase must work independently

### Rule #3: Use My GitHub Standards
- **Mandatory**: Use `shivang@crtx.in` for all commits
- **Mandatory**: Proper commit messages with Claude attribution
- **Mandatory**: Push to main branch after each atomic step
- I need the commit hash for every phase completion

## What I Expect from Coders

### Before Starting ANY Work
```
Coder must:
1. Configure git with shivang@crtx.in
2. Pull latest from repository  
3. Use context7 MCP to get current documentation
4. Present me a phase breakdown plan
5. Wait for my explicit approval
```

### During Implementation
```
Coder must:
1. Code only approved atomic steps
2. Use Playwright MCP for immediate validation
3. Access browser console for debugging
4. Commit each step to GitHub
5. Update documentation with learnings
6. Stop at phase boundaries for my validation
```

### When Presenting Completed Phase
```
I expect:
1. Clear explanation of what was built
2. GitHub commit hash
3. Playwright MCP validation results
4. Console logs and error screenshots
5. Step-by-step testing instructions
6. "git pull origin main" in the instructions
7. Wait for my validation before next phase
```

## My Project Structure

### Current Status: Documentation Complete
- 8 comprehensive docs in `/docs` folder
- Phase 1: Upload & Validation (ready to implement)
- Phase 2: AI Intelligence (design complete)
- Phase 3: Report Generation (Julius V7 port planned)

### Technology Stack I've Chosen
- **Frontend**: Next.js with TypeScript
- **UI Components**: Shadcn UI (industry standard)
- **Styling**: Tailwind CSS (via Shadcn)
- **Database**: Supabase PostgreSQL 
- **AI**: Claude for data correction
- **Testing**: Jest + Playwright + Artillery
- **Code Validation**: Playwright MCP for real-time testing
- **Analytics**: Julius V7 methodology port

## My Validation Process

### Phase 1 Testing (I will do this)
- Upload CSV files (Meta, Google, Shopify)
- Verify validation error messages work
- Test AI correction suggestions
- Confirm data appears correctly in Supabase
- Check summary tables and feedback

### Phase 2 Testing (I will do this) 
- Review data quality scores
- Validate cross-platform data alignment
- Test advanced AI corrections
- Verify backup and recovery systems

### Phase 3 Testing (I will do this)
- Generate reports for different date ranges
- Verify Julius V7 calculations are accurate
- Download and inspect all 3 CSV exports
- Test performance with large datasets

## What I Don't Want

### ❌ Don't Do This
- Start coding without my phase approval
- Build multiple phases together
- Skip documentation updates
- Commit without proper GitHub setup
- Assume I'll approve without testing
- Make up requirements not in the docs

### ✅ Do This Instead  
- Present clear phase plan and wait for approval
- Build one atomic step at a time
- Update docs with what you learned
- Use my GitHub credentials for everything
- Stop and wait for my validation
- Reference the existing 8 documentation files

## My Communication Style

### When I Approve a Phase
```
"Phase [X] plan looks good, proceed"
"Approved - start implementation"  
"Go ahead with Phase [X]"
```

### When I Need Changes
```
"Modify [specific aspect] before proceeding"
"Update the plan to include [requirement]"
"Break this down into smaller steps"
```

### When I'm Testing
```
"Hold, I need to test Phase [X] first"
"Let me validate this before next phase"
"I'll test and get back to you"
```

## My Success Criteria

### For Each Phase
- I can test it independently without coder help
- No blocking issues or confusing errors
- Documentation matches what was actually built
- GitHub history shows proper commits
- I understand what was built and why

### For Overall Project
- I can upload CSVs and get 3 reports end-to-end
- Performance is acceptable for my data volumes
- Code is clean and I can maintain it later
- Team members can access everything via GitHub

## My GitHub Repository Info

### Repository Details
- **Owner**: shivang@crtx.in
- **Location**: `/Users/shivangpatel/Documents/GitHub/crtx.in/Moi Data/DataAnalysisV2`
- **Branch**: main (always work on main)
- **Commit Format**: Must include Claude Code attribution

### Required Git Setup
```bash
git config user.email "shivang@crtx.in"
git config user.name "Shivang Patel"
```

## Context Management with context7 MCP

### What Coders Must Do
- **ALWAYS** fetch latest docs before starting work
- Reference existing documentation instead of making assumptions
- Use context7 MCP to get current project state
- Don't proceed without understanding current documentation

## Playwright MCP Integration for Code Validation

### Required Playwright MCP Usage
- **Real-time Testing**: Use Playwright MCP to test code as you write it
- **Console Access**: Capture browser console logs for debugging
- **Error Screenshots**: Take screenshots when errors occur
- **Network Monitoring**: Check API calls and responses
- **Performance Validation**: Verify load times and responsiveness

### Playwright MCP Workflow
```
1. Write code component/feature
2. Use Playwright MCP to navigate to test page
3. Capture console logs and network activity
4. Take screenshots of working/broken states
5. Document findings before committing
6. Include validation results in phase completion
```

### Console Access Protocol
```
1. Open browser via Playwright MCP
2. Navigate to application URL
3. Open developer console
4. Execute test scenarios
5. Capture console.log, console.error, console.warn
6. Screenshot any error states
7. Document console findings in commit message
```

### Key Documents to Reference
```
- project-architecture.md (system design)
- phase-1-upload-validation.md (implementation plan)
- phase-2-ai-intelligence.md (AI correction system)
- phase-3-report-generation.md (Julius V7 port)
- supabase-integration.md (database strategy)
- testing-strategy.md (validation approach)
- backup-recovery.md (best practices)
```

## Error Handling Protocol

### If Something Goes Wrong
1. **Stop immediately** and don't continue coding
2. Use Playwright MCP to capture browser state
3. Screenshot console errors and network issues
4. Document the issue clearly for me
5. Determine if it's current phase or previous phase
6. **Wait for my decision** on how to proceed
7. Commit any fixes with detailed explanation

### If Implementation Differs from Docs
1. **Stop and update documentation first**
2. Get my approval for the new approach
3. Then resume implementation
4. Commit documentation changes separately

## Quality Standards I Expect

### Code Quality
- Follows Next.js and TypeScript best practices
- Includes proper error handling and validation
- Has tests as defined in testing-strategy.md
- Validated with Playwright MCP in real browsers
- Console logs captured for debugging
- Clean, readable, and well-documented
- Committed properly to GitHub

### Documentation Quality
- Updated after each phase with learnings
- Accurate reflection of what was built
- Clear testing instructions I can follow
- Dependencies for next phase clearly stated

## My Time Investment

### I Will Spend Time On:
- Reviewing and approving phase plans
- Testing each completed phase thoroughly
- Validating that implementations match documentation
- Reviewing Playwright MCP validation results
- Analyzing console logs and error screenshots
- Providing feedback and direction for next steps

### I Won't Spend Time On:
- Debugging coder's technical issues
- Writing code myself (that's what I hired for)
- Guessing what was built without clear explanation
- Testing things that should have been tested before presenting
- Investigating issues that weren't captured with Playwright MCP

---

## Summary for Coders

**You are hired to implement my Julius V7 analytics system as a Next.js web application. I have 8 detailed documentation files ready. Your job is to implement this in 3 phases with my approval and testing at each phase boundary. Use my GitHub credentials, update documentation as you learn, and never proceed without my explicit approval.**

**I value quality over speed. Each phase must be solid before moving forward.**

*User Skill Version: 1.0*  
*Created: November 11, 2025*  
*Project: MOI Data Analytics V2*